{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHeUOEsQuUoh"
   },
   "outputs": [],
   "source": [
    "# import all required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random \n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, GRU, Dense \n",
    "from keras.models import Sequentials\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN, TGCN2\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignalBatch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error,  mean_absolute_error\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "id": "PCbQqRRgDLtN",
    "outputId": "0b4a3977-57f8-4d61-b6e3-07fa12234fe8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e136ca7b-3798-4790-a247-ce82cc150239\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>47</th>\n",
       "      <th>72</th>\n",
       "      <th>78</th>\n",
       "      <th>88</th>\n",
       "      <th>92</th>\n",
       "      <th>113</th>\n",
       "      <th>126</th>\n",
       "      <th>138</th>\n",
       "      <th>141</th>\n",
       "      <th>...</th>\n",
       "      <th>192</th>\n",
       "      <th>195</th>\n",
       "      <th>217</th>\n",
       "      <th>220</th>\n",
       "      <th>228</th>\n",
       "      <th>243</th>\n",
       "      <th>254</th>\n",
       "      <th>281</th>\n",
       "      <th>296</th>\n",
       "      <th>323</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110356</td>\n",
       "      <td>0.236273</td>\n",
       "      <td>0.143935</td>\n",
       "      <td>0.181212</td>\n",
       "      <td>0.164228</td>\n",
       "      <td>0.112551</td>\n",
       "      <td>0.126298</td>\n",
       "      <td>0.117328</td>\n",
       "      <td>0.117353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091417</td>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.066397</td>\n",
       "      <td>0.058654</td>\n",
       "      <td>0.075098</td>\n",
       "      <td>0.068696</td>\n",
       "      <td>0.054583</td>\n",
       "      <td>0.059056</td>\n",
       "      <td>0.058305</td>\n",
       "      <td>0.050814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.110356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109257</td>\n",
       "      <td>0.267139</td>\n",
       "      <td>0.095718</td>\n",
       "      <td>0.144390</td>\n",
       "      <td>0.208583</td>\n",
       "      <td>0.132625</td>\n",
       "      <td>0.079494</td>\n",
       "      <td>0.097987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087746</td>\n",
       "      <td>0.096880</td>\n",
       "      <td>0.102601</td>\n",
       "      <td>0.097302</td>\n",
       "      <td>0.082217</td>\n",
       "      <td>0.069394</td>\n",
       "      <td>0.084349</td>\n",
       "      <td>0.071076</td>\n",
       "      <td>0.064031</td>\n",
       "      <td>0.047170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.236273</td>\n",
       "      <td>0.109257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174832</td>\n",
       "      <td>0.645102</td>\n",
       "      <td>0.325035</td>\n",
       "      <td>0.148464</td>\n",
       "      <td>0.222798</td>\n",
       "      <td>0.221339</td>\n",
       "      <td>0.229932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147244</td>\n",
       "      <td>0.122364</td>\n",
       "      <td>0.082703</td>\n",
       "      <td>0.068796</td>\n",
       "      <td>0.107523</td>\n",
       "      <td>0.096458</td>\n",
       "      <td>0.064189</td>\n",
       "      <td>0.076388</td>\n",
       "      <td>0.076561</td>\n",
       "      <td>0.064459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.143935</td>\n",
       "      <td>0.267139</td>\n",
       "      <td>0.174832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145813</td>\n",
       "      <td>0.313177</td>\n",
       "      <td>0.442175</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.113106</td>\n",
       "      <td>0.153721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126098</td>\n",
       "      <td>0.135770</td>\n",
       "      <td>0.116351</td>\n",
       "      <td>0.097973</td>\n",
       "      <td>0.109166</td>\n",
       "      <td>0.089090</td>\n",
       "      <td>0.086394</td>\n",
       "      <td>0.084737</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.056153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.181212</td>\n",
       "      <td>0.095718</td>\n",
       "      <td>0.645102</td>\n",
       "      <td>0.145813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260419</td>\n",
       "      <td>0.133522</td>\n",
       "      <td>0.211733</td>\n",
       "      <td>0.330050</td>\n",
       "      <td>0.275207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166278</td>\n",
       "      <td>0.128027</td>\n",
       "      <td>0.081739</td>\n",
       "      <td>0.067254</td>\n",
       "      <td>0.115331</td>\n",
       "      <td>0.106098</td>\n",
       "      <td>0.063360</td>\n",
       "      <td>0.079434</td>\n",
       "      <td>0.081462</td>\n",
       "      <td>0.070607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.164228</td>\n",
       "      <td>0.144390</td>\n",
       "      <td>0.325035</td>\n",
       "      <td>0.313177</td>\n",
       "      <td>0.260419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271064</td>\n",
       "      <td>0.540075</td>\n",
       "      <td>0.176855</td>\n",
       "      <td>0.278847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180396</td>\n",
       "      <td>0.167196</td>\n",
       "      <td>0.109029</td>\n",
       "      <td>0.086970</td>\n",
       "      <td>0.133413</td>\n",
       "      <td>0.109384</td>\n",
       "      <td>0.079381</td>\n",
       "      <td>0.091725</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.065522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.112551</td>\n",
       "      <td>0.208583</td>\n",
       "      <td>0.148464</td>\n",
       "      <td>0.442175</td>\n",
       "      <td>0.133522</td>\n",
       "      <td>0.271064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308841</td>\n",
       "      <td>0.114254</td>\n",
       "      <td>0.168040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149161</td>\n",
       "      <td>0.180343</td>\n",
       "      <td>0.157361</td>\n",
       "      <td>0.122457</td>\n",
       "      <td>0.135411</td>\n",
       "      <td>0.103990</td>\n",
       "      <td>0.105806</td>\n",
       "      <td>0.103478</td>\n",
       "      <td>0.091317</td>\n",
       "      <td>0.060882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.126298</td>\n",
       "      <td>0.132625</td>\n",
       "      <td>0.222798</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.211733</td>\n",
       "      <td>0.540075</td>\n",
       "      <td>0.308841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180816</td>\n",
       "      <td>0.365729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247734</td>\n",
       "      <td>0.241840</td>\n",
       "      <td>0.131396</td>\n",
       "      <td>0.098479</td>\n",
       "      <td>0.175335</td>\n",
       "      <td>0.133346</td>\n",
       "      <td>0.089911</td>\n",
       "      <td>0.110489</td>\n",
       "      <td>0.104375</td>\n",
       "      <td>0.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.117328</td>\n",
       "      <td>0.079494</td>\n",
       "      <td>0.221339</td>\n",
       "      <td>0.113106</td>\n",
       "      <td>0.330050</td>\n",
       "      <td>0.176855</td>\n",
       "      <td>0.114254</td>\n",
       "      <td>0.180816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223056</td>\n",
       "      <td>0.144352</td>\n",
       "      <td>0.083149</td>\n",
       "      <td>0.066961</td>\n",
       "      <td>0.139938</td>\n",
       "      <td>0.138718</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.090053</td>\n",
       "      <td>0.097515</td>\n",
       "      <td>0.089265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.117353</td>\n",
       "      <td>0.097987</td>\n",
       "      <td>0.229932</td>\n",
       "      <td>0.153721</td>\n",
       "      <td>0.275207</td>\n",
       "      <td>0.278847</td>\n",
       "      <td>0.168040</td>\n",
       "      <td>0.365729</td>\n",
       "      <td>0.331141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409101</td>\n",
       "      <td>0.234668</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.083599</td>\n",
       "      <td>0.198333</td>\n",
       "      <td>0.165686</td>\n",
       "      <td>0.078932</td>\n",
       "      <td>0.111642</td>\n",
       "      <td>0.114614</td>\n",
       "      <td>0.085327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.124251</td>\n",
       "      <td>0.107809</td>\n",
       "      <td>0.248793</td>\n",
       "      <td>0.179284</td>\n",
       "      <td>0.274416</td>\n",
       "      <td>0.367075</td>\n",
       "      <td>0.197347</td>\n",
       "      <td>0.545834</td>\n",
       "      <td>0.266708</td>\n",
       "      <td>1.075541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339723</td>\n",
       "      <td>0.238133</td>\n",
       "      <td>0.115072</td>\n",
       "      <td>0.087317</td>\n",
       "      <td>0.188930</td>\n",
       "      <td>0.151688</td>\n",
       "      <td>0.081598</td>\n",
       "      <td>0.110142</td>\n",
       "      <td>0.109845</td>\n",
       "      <td>0.079752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.115321</td>\n",
       "      <td>0.124468</td>\n",
       "      <td>0.196040</td>\n",
       "      <td>0.220380</td>\n",
       "      <td>0.194237</td>\n",
       "      <td>0.379903</td>\n",
       "      <td>0.286935</td>\n",
       "      <td>1.266551</td>\n",
       "      <td>0.181021</td>\n",
       "      <td>0.391533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294498</td>\n",
       "      <td>0.298593</td>\n",
       "      <td>0.141066</td>\n",
       "      <td>0.102567</td>\n",
       "      <td>0.203267</td>\n",
       "      <td>0.147834</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>0.113710</td>\n",
       "      <td>0.075350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.095410</td>\n",
       "      <td>0.100376</td>\n",
       "      <td>0.152651</td>\n",
       "      <td>0.150958</td>\n",
       "      <td>0.163359</td>\n",
       "      <td>0.215033</td>\n",
       "      <td>0.191733</td>\n",
       "      <td>0.344411</td>\n",
       "      <td>0.187088</td>\n",
       "      <td>0.389015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643446</td>\n",
       "      <td>0.589755</td>\n",
       "      <td>0.149415</td>\n",
       "      <td>0.103698</td>\n",
       "      <td>0.350084</td>\n",
       "      <td>0.216424</td>\n",
       "      <td>0.097819</td>\n",
       "      <td>0.152886</td>\n",
       "      <td>0.148460</td>\n",
       "      <td>0.088951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.082770</td>\n",
       "      <td>0.128353</td>\n",
       "      <td>0.109845</td>\n",
       "      <td>0.170751</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.162230</td>\n",
       "      <td>0.277714</td>\n",
       "      <td>0.215382</td>\n",
       "      <td>0.105748</td>\n",
       "      <td>0.155032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172656</td>\n",
       "      <td>0.287938</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.179845</td>\n",
       "      <td>0.197353</td>\n",
       "      <td>0.134133</td>\n",
       "      <td>0.154318</td>\n",
       "      <td>0.159274</td>\n",
       "      <td>0.125521</td>\n",
       "      <td>0.069535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.091417</td>\n",
       "      <td>0.087746</td>\n",
       "      <td>0.147244</td>\n",
       "      <td>0.126098</td>\n",
       "      <td>0.166278</td>\n",
       "      <td>0.180396</td>\n",
       "      <td>0.149161</td>\n",
       "      <td>0.247734</td>\n",
       "      <td>0.223056</td>\n",
       "      <td>0.409101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383024</td>\n",
       "      <td>0.126843</td>\n",
       "      <td>0.091766</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.274047</td>\n",
       "      <td>0.088265</td>\n",
       "      <td>0.149370</td>\n",
       "      <td>0.159146</td>\n",
       "      <td>0.101223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.096880</td>\n",
       "      <td>0.122364</td>\n",
       "      <td>0.135770</td>\n",
       "      <td>0.128027</td>\n",
       "      <td>0.167196</td>\n",
       "      <td>0.180343</td>\n",
       "      <td>0.241840</td>\n",
       "      <td>0.144352</td>\n",
       "      <td>0.234668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189541</td>\n",
       "      <td>0.120511</td>\n",
       "      <td>0.543167</td>\n",
       "      <td>0.240868</td>\n",
       "      <td>0.114620</td>\n",
       "      <td>0.201828</td>\n",
       "      <td>0.180192</td>\n",
       "      <td>0.090280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.066397</td>\n",
       "      <td>0.102601</td>\n",
       "      <td>0.082703</td>\n",
       "      <td>0.116351</td>\n",
       "      <td>0.081739</td>\n",
       "      <td>0.109029</td>\n",
       "      <td>0.157361</td>\n",
       "      <td>0.131396</td>\n",
       "      <td>0.083149</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126843</td>\n",
       "      <td>0.189541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328968</td>\n",
       "      <td>0.162218</td>\n",
       "      <td>0.120425</td>\n",
       "      <td>0.280409</td>\n",
       "      <td>0.189488</td>\n",
       "      <td>0.130992</td>\n",
       "      <td>0.067329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.058654</td>\n",
       "      <td>0.097302</td>\n",
       "      <td>0.068796</td>\n",
       "      <td>0.097973</td>\n",
       "      <td>0.067254</td>\n",
       "      <td>0.086970</td>\n",
       "      <td>0.122457</td>\n",
       "      <td>0.098479</td>\n",
       "      <td>0.066961</td>\n",
       "      <td>0.083599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091766</td>\n",
       "      <td>0.120511</td>\n",
       "      <td>0.328968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108908</td>\n",
       "      <td>0.088921</td>\n",
       "      <td>0.618468</td>\n",
       "      <td>0.130787</td>\n",
       "      <td>0.098220</td>\n",
       "      <td>0.056897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.075098</td>\n",
       "      <td>0.082217</td>\n",
       "      <td>0.107523</td>\n",
       "      <td>0.109166</td>\n",
       "      <td>0.115331</td>\n",
       "      <td>0.133413</td>\n",
       "      <td>0.135411</td>\n",
       "      <td>0.175335</td>\n",
       "      <td>0.139938</td>\n",
       "      <td>0.198333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.543167</td>\n",
       "      <td>0.162218</td>\n",
       "      <td>0.108908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.418550</td>\n",
       "      <td>0.107466</td>\n",
       "      <td>0.251363</td>\n",
       "      <td>0.257507</td>\n",
       "      <td>0.107236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.068696</td>\n",
       "      <td>0.069394</td>\n",
       "      <td>0.096458</td>\n",
       "      <td>0.089090</td>\n",
       "      <td>0.106098</td>\n",
       "      <td>0.109384</td>\n",
       "      <td>0.103990</td>\n",
       "      <td>0.133346</td>\n",
       "      <td>0.138718</td>\n",
       "      <td>0.165686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274047</td>\n",
       "      <td>0.240868</td>\n",
       "      <td>0.120425</td>\n",
       "      <td>0.088921</td>\n",
       "      <td>0.418550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089666</td>\n",
       "      <td>0.213903</td>\n",
       "      <td>0.323453</td>\n",
       "      <td>0.144101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.054583</td>\n",
       "      <td>0.084349</td>\n",
       "      <td>0.064189</td>\n",
       "      <td>0.086394</td>\n",
       "      <td>0.063360</td>\n",
       "      <td>0.079381</td>\n",
       "      <td>0.105806</td>\n",
       "      <td>0.089911</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.078932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088265</td>\n",
       "      <td>0.114620</td>\n",
       "      <td>0.280409</td>\n",
       "      <td>0.618468</td>\n",
       "      <td>0.107466</td>\n",
       "      <td>0.089666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141058</td>\n",
       "      <td>0.103476</td>\n",
       "      <td>0.058424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.059056</td>\n",
       "      <td>0.071076</td>\n",
       "      <td>0.076388</td>\n",
       "      <td>0.084737</td>\n",
       "      <td>0.079434</td>\n",
       "      <td>0.091725</td>\n",
       "      <td>0.103478</td>\n",
       "      <td>0.110489</td>\n",
       "      <td>0.090053</td>\n",
       "      <td>0.111642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149370</td>\n",
       "      <td>0.201828</td>\n",
       "      <td>0.189488</td>\n",
       "      <td>0.130787</td>\n",
       "      <td>0.251363</td>\n",
       "      <td>0.213903</td>\n",
       "      <td>0.141058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388382</td>\n",
       "      <td>0.099729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.058305</td>\n",
       "      <td>0.064031</td>\n",
       "      <td>0.076561</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.081462</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.091317</td>\n",
       "      <td>0.104375</td>\n",
       "      <td>0.097515</td>\n",
       "      <td>0.114614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159146</td>\n",
       "      <td>0.180192</td>\n",
       "      <td>0.130992</td>\n",
       "      <td>0.098220</td>\n",
       "      <td>0.257507</td>\n",
       "      <td>0.323453</td>\n",
       "      <td>0.103476</td>\n",
       "      <td>0.388382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.050814</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.064459</td>\n",
       "      <td>0.056153</td>\n",
       "      <td>0.070607</td>\n",
       "      <td>0.065522</td>\n",
       "      <td>0.060882</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.089265</td>\n",
       "      <td>0.085327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101223</td>\n",
       "      <td>0.090280</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>0.056897</td>\n",
       "      <td>0.107236</td>\n",
       "      <td>0.144101</td>\n",
       "      <td>0.058424</td>\n",
       "      <td>0.099729</td>\n",
       "      <td>0.134183</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows Ã— 24 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e136ca7b-3798-4790-a247-ce82cc150239')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e136ca7b-3798-4790-a247-ce82cc150239 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e136ca7b-3798-4790-a247-ce82cc150239');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          5         47        72        78        88        92        113  \\\n",
       "5    0.000000  0.110356  0.236273  0.143935  0.181212  0.164228  0.112551   \n",
       "47   0.110356  0.000000  0.109257  0.267139  0.095718  0.144390  0.208583   \n",
       "72   0.236273  0.109257  0.000000  0.174832  0.645102  0.325035  0.148464   \n",
       "78   0.143935  0.267139  0.174832  0.000000  0.145813  0.313177  0.442175   \n",
       "88   0.181212  0.095718  0.645102  0.145813  0.000000  0.260419  0.133522   \n",
       "92   0.164228  0.144390  0.325035  0.313177  0.260419  0.000000  0.271064   \n",
       "113  0.112551  0.208583  0.148464  0.442175  0.133522  0.271064  0.000000   \n",
       "126  0.126298  0.132625  0.222798  0.254499  0.211733  0.540075  0.308841   \n",
       "138  0.117328  0.079494  0.221339  0.113106  0.330050  0.176855  0.114254   \n",
       "141  0.117353  0.097987  0.229932  0.153721  0.275207  0.278847  0.168040   \n",
       "142  0.124251  0.107809  0.248793  0.179284  0.274416  0.367075  0.197347   \n",
       "143  0.115321  0.124468  0.196040  0.220380  0.194237  0.379903  0.286935   \n",
       "177  0.095410  0.100376  0.152651  0.150958  0.163359  0.215033  0.191733   \n",
       "181  0.082770  0.128353  0.109845  0.170751  0.107200  0.162230  0.277714   \n",
       "192  0.091417  0.087746  0.147244  0.126098  0.166278  0.180396  0.149161   \n",
       "195  0.083470  0.096880  0.122364  0.135770  0.128027  0.167196  0.180343   \n",
       "217  0.066397  0.102601  0.082703  0.116351  0.081739  0.109029  0.157361   \n",
       "220  0.058654  0.097302  0.068796  0.097973  0.067254  0.086970  0.122457   \n",
       "228  0.075098  0.082217  0.107523  0.109166  0.115331  0.133413  0.135411   \n",
       "243  0.068696  0.069394  0.096458  0.089090  0.106098  0.109384  0.103990   \n",
       "254  0.054583  0.084349  0.064189  0.086394  0.063360  0.079381  0.105806   \n",
       "281  0.059056  0.071076  0.076388  0.084737  0.079434  0.091725  0.103478   \n",
       "296  0.058305  0.064031  0.076561  0.077548  0.081462  0.087882  0.091317   \n",
       "323  0.050814  0.047170  0.064459  0.056153  0.070607  0.065522  0.060882   \n",
       "\n",
       "          126       138       141  ...       192       195       217  \\\n",
       "5    0.126298  0.117328  0.117353  ...  0.091417  0.083470  0.066397   \n",
       "47   0.132625  0.079494  0.097987  ...  0.087746  0.096880  0.102601   \n",
       "72   0.222798  0.221339  0.229932  ...  0.147244  0.122364  0.082703   \n",
       "78   0.254499  0.113106  0.153721  ...  0.126098  0.135770  0.116351   \n",
       "88   0.211733  0.330050  0.275207  ...  0.166278  0.128027  0.081739   \n",
       "92   0.540075  0.176855  0.278847  ...  0.180396  0.167196  0.109029   \n",
       "113  0.308841  0.114254  0.168040  ...  0.149161  0.180343  0.157361   \n",
       "126  0.000000  0.180816  0.365729  ...  0.247734  0.241840  0.131396   \n",
       "138  0.180816  0.000000  0.331141  ...  0.223056  0.144352  0.083149   \n",
       "141  0.365729  0.331141  0.000000  ...  0.409101  0.234668  0.109792   \n",
       "142  0.545834  0.266708  1.075541  ...  0.339723  0.238133  0.115072   \n",
       "143  1.266551  0.181021  0.391533  ...  0.294498  0.298593  0.141066   \n",
       "177  0.344411  0.187088  0.389015  ...  0.643446  0.589755  0.149415   \n",
       "181  0.215382  0.105748  0.155032  ...  0.172656  0.287938  0.332458   \n",
       "192  0.247734  0.223056  0.409101  ...  0.000000  0.383024  0.126843   \n",
       "195  0.241840  0.144352  0.234668  ...  0.383024  0.000000  0.189541   \n",
       "217  0.131396  0.083149  0.109792  ...  0.126843  0.189541  0.000000   \n",
       "220  0.098479  0.066961  0.083599  ...  0.091766  0.120511  0.328968   \n",
       "228  0.175335  0.139938  0.198333  ...  0.368000  0.543167  0.162218   \n",
       "243  0.133346  0.138718  0.165686  ...  0.274047  0.240868  0.120425   \n",
       "254  0.089911  0.064239  0.078932  ...  0.088265  0.114620  0.280409   \n",
       "281  0.110489  0.090053  0.111642  ...  0.149370  0.201828  0.189488   \n",
       "296  0.104375  0.097515  0.114614  ...  0.159146  0.180192  0.130992   \n",
       "323  0.071900  0.089265  0.085327  ...  0.101223  0.090280  0.067329   \n",
       "\n",
       "          220       228       243       254       281       296       323  \n",
       "5    0.058654  0.075098  0.068696  0.054583  0.059056  0.058305  0.050814  \n",
       "47   0.097302  0.082217  0.069394  0.084349  0.071076  0.064031  0.047170  \n",
       "72   0.068796  0.107523  0.096458  0.064189  0.076388  0.076561  0.064459  \n",
       "78   0.097973  0.109166  0.089090  0.086394  0.084737  0.077548  0.056153  \n",
       "88   0.067254  0.115331  0.106098  0.063360  0.079434  0.081462  0.070607  \n",
       "92   0.086970  0.133413  0.109384  0.079381  0.091725  0.087882  0.065522  \n",
       "113  0.122457  0.135411  0.103990  0.105806  0.103478  0.091317  0.060882  \n",
       "126  0.098479  0.175335  0.133346  0.089911  0.110489  0.104375  0.071900  \n",
       "138  0.066961  0.139938  0.138718  0.064239  0.090053  0.097515  0.089265  \n",
       "141  0.083599  0.198333  0.165686  0.078932  0.111642  0.114614  0.085327  \n",
       "142  0.087317  0.188930  0.151688  0.081598  0.110142  0.109845  0.079752  \n",
       "143  0.102567  0.203267  0.147834  0.094033  0.120828  0.113710  0.075350  \n",
       "177  0.103698  0.350084  0.216424  0.097819  0.152886  0.148460  0.088951  \n",
       "181  0.179845  0.197353  0.134133  0.154318  0.159274  0.125521  0.069535  \n",
       "192  0.091766  0.368000  0.274047  0.088265  0.149370  0.159146  0.101223  \n",
       "195  0.120511  0.543167  0.240868  0.114620  0.201828  0.180192  0.090280  \n",
       "217  0.328968  0.162218  0.120425  0.280409  0.189488  0.130992  0.067329  \n",
       "220  0.000000  0.108908  0.088921  0.618468  0.130787  0.098220  0.056897  \n",
       "228  0.108908  0.000000  0.418550  0.107466  0.251363  0.257507  0.107236  \n",
       "243  0.088921  0.418550  0.000000  0.089666  0.213903  0.323453  0.144101  \n",
       "254  0.618468  0.107466  0.089666  0.000000  0.141058  0.103476  0.058424  \n",
       "281  0.130787  0.251363  0.213903  0.141058  0.000000  0.388382  0.099729  \n",
       "296  0.098220  0.257507  0.323453  0.103476  0.388382  0.000000  0.134183  \n",
       "323  0.056897  0.107236  0.144101  0.058424  0.099729  0.134183  0.000000  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating adjacency matrix\n",
    "\n",
    "data_adj= pd.read_csv('/content/distanceNodes.txt', encoding='utf8', delimiter='\\t')\n",
    "\n",
    "#create new column calling Distance_KM, which calculates distance between nodes in km\n",
    "data_adj['Distance_KM']=data_adj['NEAR_DIST']/1000\n",
    "\n",
    "#  Change the nodes id\n",
    "replacement_mapping_dict = {\n",
    "    0: 141, 1: 143, 2: 195, 3: 181, 4: 5, 5: 88, 6: 138, 7: 254, 8: 142, 9: 113, 10: 192, 11: 243, 12: 78, 13: 92, \n",
    "    14: 177, 15: 126, 16: 228, 17: 47, 18: 220, 19: 72, 20: 281, 21: 323, 22:217, 23:296\n",
    "}\n",
    "data_fin = data_adj[[\"IN_FID\", \"NEAR_FID\"]].replace(replacement_mapping_dict)\n",
    "\n",
    "# Replace columns with the new created columns\n",
    "data_adj['IN_FID'] = data_fin[\"IN_FID\"]\n",
    "data_adj['NEAR_FID'] = data_fin[\"NEAR_FID\"]\n",
    "\n",
    "### create Adjacency matrix and replace column and index names according to grid cells id where air quality stations are located\n",
    "\n",
    "am = pd.DataFrame(np.zeros(shape=(24, 24)))\n",
    "am.rename(columns=replacement_mapping_dict, index =replacement_mapping_dict, inplace=True)\n",
    "adj_mat = am.sort_index(axis=1)\n",
    "adj_mat_complete = adj_mat.sort_index()\n",
    "\n",
    "\n",
    "### Adjacency matrix\n",
    "\n",
    "for i in data_adj.IN_FID.unique():\n",
    "    for j in data_adj.NEAR_FID.unique():\n",
    "        if i==j:\n",
    "            adj_mat_complete.at[i,j]=0\n",
    "        else:      \n",
    "            adj_mat_complete.at[i,j]=1/data_adj.loc[(data_adj['IN_FID'] == i) & (data_adj['NEAR_FID'] == j)]['Distance_KM']\n",
    "   \n",
    "      \n",
    "adj_mat_complete  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eObnLILBecy6"
   },
   "outputs": [],
   "source": [
    "# set the seed in order to provide reproducibility of the code\n",
    "\n",
    "rnd_seed = 11\n",
    "\n",
    "def set_seed(seed_num) -> None:\n",
    "    random.seed(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    tf.experimental.numpy.random.seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    torch.manual_seed(seed_num)\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed_num)\n",
    "    print(f\"Random seed set as {seed_num}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4dl8jx5en9j"
   },
   "outputs": [],
   "source": [
    "# read the file containing nodes (air quality monitoring stations) features as pandas dataframe\n",
    "Mad_data_2019 = pd.read_csv('/content/Mad_Station_2019.csv')\n",
    "Mad_data_2022 = pd.read_csv('/content/Mad_Station_2022.csv')\n",
    "\n",
    "# to delete 'windDir' column as we will not need it for further analysis.\n",
    "Mad_data_2019 = Mad_data_2019.drop(['windDir'], axis=1)\n",
    "Mad_data_2022 = Mad_data_2022.drop(['windDir'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vUWMs4WCl1c",
    "outputId": "ed318f5f-ad39-46bf-bafd-9f25a00e5c59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4343, 24, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dataframes to numpy arrays\n",
    "\n",
    "fin_data=Mad_data_2019.to_numpy().reshape(-1, 24, 18)\n",
    "fin_data_test=Mad_data_2022.to_numpy().reshape(-1, 24,18)\n",
    "fin_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lv-G6JcqZzPC"
   },
   "outputs": [],
   "source": [
    "# the function to return data in original scale (reversing Z score)\n",
    "\n",
    "def reverse_zscore(pandas_series, mean, std):\n",
    "    '''Mean and standard deviation should be of original variable before standardisation'''\n",
    "    yis=pandas_series*std+mean\n",
    "    return yis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Rny1xvRsDWh"
   },
   "source": [
    "Create the models and run them (A3T-GCN, TGCN, LSTM and GRU)\n",
    "\n",
    "# A3T-GCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_wOrIaC5zFf"
   },
   "outputs": [],
   "source": [
    "#to convert adjacency dataframe to numpy\n",
    "adj = adj_mat_complete.to_numpy()\n",
    "\n",
    "# standardise train data\n",
    "\n",
    "data = fin_data.transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "data = data.astype(np.float32)\n",
    "\n",
    "# standardise (via Z-Score Method)\n",
    "means = np.mean(data, axis=(0, 2))\n",
    "data_norm= data-means.reshape(1, -1, 1)\n",
    "stds = np.std(data_norm, axis=(0, 2))\n",
    "data_norm= data_norm/ stds.reshape(1, -1, 1)\n",
    "\n",
    "#to convert adjacency matrix and standardised train data to torch\n",
    "adj = torch.from_numpy(adj)\n",
    "data_norm= torch.from_numpy(data_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RWv84L955Cc"
   },
   "outputs": [],
   "source": [
    "# standardise test data using means and standard deviation of train set\n",
    "\n",
    "data_test = fin_data_test.transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "data_test = data_test.astype(np.float32)\n",
    "data_test_norm= data_test- means.reshape(1, -1, 1)\n",
    "data_test_norm= data_test_norm/ stds.reshape(1, -1, 1)\n",
    "\n",
    "#to convert standardised test data to torch\n",
    "data_test_norm = torch.from_numpy(data_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1j9q2CEB-Om6",
    "outputId": "5cecdd76-f202-4470-d8ab-5b2a5d344070"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 24])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdK3LHqP-QaQ",
    "outputId": "264d8054-6c9d-493f-face-38e064ae02f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 18, 4343])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENE2S1bjgsYb"
   },
   "outputs": [],
   "source": [
    "#from adjacency matrix extract the edge indices and edge weights\n",
    "\n",
    "edge_indices, values = dense_to_sparse(adj)\n",
    "edge_indices = edge_indices.numpy()\n",
    "values = values.numpy()\n",
    "edges = edge_indices\n",
    "edge_weights = values\n",
    "batch =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ie4hIMlm-pcg",
    "outputId": "01e4d39b-a30c-4c65-eb78-03df15308e86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 552)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qm83WCRV-rtQ",
    "outputId": "549ea40d-1287-4565-f2cc-350be46b0dcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibGbQjvdS0F6"
   },
   "outputs": [],
   "source": [
    "class MadridDatasetLoader(object):\n",
    "    \"\"\"The dataset is based on 24 stations (nodes) each having 18 features (nodal features) \n",
    "    and 276 edges connecting each pair of nodes, the edge weights are the distance between the edges.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_norm, edges, edge_weights, batch):\n",
    "        super(MadridDatasetLoader, self).__init__()\n",
    "        \n",
    "        self.data_norm = data_norm\n",
    "        self.edges = edges \n",
    "        self.edge_weights= edge_weights\n",
    "        self.batch = batch\n",
    "\n",
    "\n",
    "    def _generate_task(self, num_timesteps_in: int = 6, num_timesteps_out: int = 6):\n",
    "        \"\"\"Uses the node features of the graph and generates a feature/target\n",
    "        relationship of the shape\n",
    "        (num_nodes, num_node_features, num_timesteps_in) -> (num_nodes, num_timesteps_out)\n",
    "        \n",
    "\n",
    "        Args:\n",
    "            num_timesteps_in (int): number of timesteps the sequence model sees\n",
    "            num_timesteps_out (int): number of timesteps the sequence model has to predict\n",
    "        \"\"\"\n",
    "        time_steps_starter =   0 # it can be assigned as one of the following {0, 12, 24, 36}\n",
    "        indices = [\n",
    "            (i, i +time_steps_starter+ (num_timesteps_in + num_timesteps_out))\n",
    "            for i in range(self.data_norm.shape[2] - (time_steps_starter+num_timesteps_in + num_timesteps_out) + 1)\n",
    "        ]\n",
    "        print(indices)\n",
    "        # Generate observations\n",
    "        features, target = [], []\n",
    "        for i, j in indices:\n",
    "            features.append((self.data_norm[:, :, i : i + num_timesteps_in]).numpy())\n",
    "            target.append((self.data_norm[  :, 0, i + num_timesteps_in +time_steps_starter: j]).numpy())\n",
    "\n",
    "        self.features = features\n",
    "        self.targets = target\n",
    "\n",
    "    def get_dataset(\n",
    "        self, num_timesteps_in: int = 6, num_timesteps_out: int = 6\n",
    "    ) -> StaticGraphTemporalSignal:\n",
    "        \"\"\"Returns data iterator for the dataset as an instance of the\n",
    "        static graph temporal signal class.\n",
    "\n",
    "        Return types:\n",
    "            * **dataset** *(StaticGraphTemporalSignal)* - The forecasting dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._generate_task(num_timesteps_in, num_timesteps_out)\n",
    "        dataset = StaticGraphTemporalSignalBatch(\n",
    "            self.edges, self.edge_weights, self.features, self.targets, self.batch\n",
    "        )\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCa7JCuY-syX"
   },
   "outputs": [],
   "source": [
    "loader = MadridDatasetLoader(data_test_norm, edges, edge_weights, batch)\n",
    "dataset_test = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
    "print(\"Dataset type:  \", dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQ2A9CVG-wn2"
   },
   "outputs": [],
   "source": [
    "loader = MadridDatasetLoader(data_norm, edges, edge_weights, batch)\n",
    "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
    "print(\"Dataset type:  \", dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3T-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define A3T-GCN\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    set_seed(rnd_seed)\n",
    "\n",
    "unit_num  = 256  # This is number of units in order to construct the architecture of the A3T-GCN. \n",
    "  \n",
    "class TemporalGNN(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods):\n",
    "        super(TemporalGNN, self).__init__()\n",
    "        # Attention Temporal Graph Convolutional Cell\n",
    "        self.tgnn = A3TGCN(in_channels=node_features, \n",
    "                        out_channels=unit_num, \n",
    "                        periods=periods)\n",
    "        # Equals single-shot prediction\n",
    "        self.linear = torch.nn.Linear(unit_num, periods)\n",
    "\n",
    "    def forward(self, x, edge_index,  edge_weight):\n",
    "        \"\"\"\n",
    "        x = Node features for T time steps\n",
    "        edge_index = Graph edge indices\n",
    "        \"\"\"\n",
    "        h = self.tgnn(x, edge_index,  edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "TemporalGNN(node_features=18, periods=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fNSDo75_FHfT"
   },
   "outputs": [],
   "source": [
    "# GPU support\n",
    "device = torch.device('cpu') # cuda\n",
    "\n",
    "\n",
    "# Create model and optimizers\n",
    "model = TemporalGNN(node_features=18, periods=12).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "print(\"Running training...\")\n",
    "for epoch in range(100): \n",
    "    loss = 0\n",
    "    step = 0\n",
    "    for snapshot in dataset:\n",
    "        snapshot = snapshot.to(device)\n",
    "        # Get model predictions\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        # Mean Squared Error\n",
    "        loss = loss + torch.mean((y_hat-snapshot.y)**2) \n",
    "        step += 1\n",
    "        \n",
    "\n",
    "    loss = loss / (step + 1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZZBeg07mZoXh"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "loss = 0\n",
    "step = 0\n",
    "\n",
    "# Store for analysis\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for snapshot in dataset_test:\n",
    "    snapshot = snapshot.to(device)\n",
    "    # Get predictions\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    yhat_reverse = reverse_zscore(y_hat, means[0], stds[0])\n",
    "    snapshot.y_reverse = reverse_zscore(snapshot.y, means[0], stds[0])\n",
    "    # Root Mean Squared Error\n",
    "    loss = loss + torch.sqrt(torch.mean((yhat_reverse-snapshot.y_reverse)**2)) \n",
    "    # Store for analysis below\n",
    "    labels.append(snapshot.y_reverse)\n",
    "    predictions.append(yhat_reverse)    \n",
    "    step += 1\n",
    "\n",
    "loss = loss / (step+1)\n",
    "loss = loss.item()\n",
    "print(\"Test RMSE: {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqmZM5qH_HgJ"
   },
   "outputs": [],
   "source": [
    "# calculated for all nodes\n",
    "ALLNode_pred = []\n",
    "ALLNode_true = []\n",
    "for item in predictions:\n",
    "    for node in range(24):\n",
    "        for hour in range(12):\n",
    "            ALLNode_pred.append(item[node][hour].detach().cpu().numpy().item(0))\n",
    "\n",
    "\n",
    "for item in labels:\n",
    "    for node in range(24):\n",
    "        for hour in range(12):\n",
    "            ALLNode_true.append(item[node][hour].detach().cpu().numpy().item(0))\n",
    "\n",
    "\n",
    "ALLNode_pred_np = np.array(ALLNode_pred)\n",
    "ALLNode_pred_np_resh = ALLNode_pred_np.reshape(-1, 24, 12)\n",
    "ALLNode_true_np = np.array(ALLNode_true)\n",
    "ALLNode_true_np_resh = ALLNode_true_np.reshape(-1, 24, 12)\n",
    "\n",
    "\n",
    "scipy.stats.pearsonr(ALLNode_pred_np, ALLNode_true_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a6TMMKbprlc"
   },
   "source": [
    "# TGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAlD0FbX9sIi"
   },
   "outputs": [],
   "source": [
    "#to convert adjacency dataframe to numpy\n",
    "adj = adj_mat_complete.to_numpy()\n",
    "\n",
    "# standardise train data\n",
    "\n",
    "data = fin_data.transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "data = data.astype(np.float32)\n",
    "\n",
    "# standardise (via Z-Score Method)\n",
    "means = np.mean(data, axis=(0, 2))\n",
    "data_norm= data-means.reshape(1, -1, 1)\n",
    "stds = np.std(data_norm, axis=(0, 2))\n",
    "data_norm= data_norm/ stds.reshape(1, -1, 1)\n",
    "\n",
    "#to convert adjacency matrix and standardised train data to torch\n",
    "adj = torch.from_numpy(adj)\n",
    "data_norm= torch.from_numpy(data_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eA65rwi9vpH"
   },
   "outputs": [],
   "source": [
    "# standardise test data using means and standard deviation of train set\n",
    "\n",
    "data_test = fin_data_test.transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "data_test = data_test.astype(np.float32)\n",
    "data_test_norm= data_test- means.reshape(1, -1, 1)\n",
    "data_test_norm= data_test_norm/ stds.reshape(1, -1, 1)\n",
    "\n",
    "#to convert standardised test data to torch\n",
    "data_test_norm = torch.from_numpy(data_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fS3BS3j4p-GT",
    "outputId": "78f079be-16f7-49c0-b03a-bfd2be7d91c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 24])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2kiy4ndqBlM",
    "outputId": "59ceca56-7b29-4b27-a675-5a2e1609aeba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 18, 4343])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vh8TX71qFHL"
   },
   "outputs": [],
   "source": [
    "#from adjacency matrix extract the edge indices and edge weights\n",
    "\n",
    "edge_indices, values = dense_to_sparse(adj)\n",
    "edge_indices = edge_indices.numpy()\n",
    "values = values.numpy()\n",
    "edges = edge_indices\n",
    "edge_weights = values\n",
    "batch =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjOsJKf0qLoM",
    "outputId": "59c019f2-8345-4d1e-f161-dc95f4d7464d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 552)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDg-uTUxqPWd",
    "outputId": "99762227-c252-475b-d73c-ec4144725d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3NBsG1sqSgP"
   },
   "outputs": [],
   "source": [
    "class MadridDatasetLoader(object):\n",
    "    \"\"\"The dataset is based on 24 stations (nodes) each having 18 features (nodal features) \n",
    "    and 276 edges connecting each pair of nodes, the edge weights are the distance between the edges.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_norm, edges, edge_weights, batch):\n",
    "        super(MadridDatasetLoader, self).__init__()\n",
    "        \n",
    "        self.data_norm = data_norm\n",
    "        self.edges = edges \n",
    "        self.edge_weights= edge_weights\n",
    "        self.batch = batch\n",
    "\n",
    "\n",
    "    def _generate_task(self, num_timesteps_in: int = 6, num_timesteps_out: int = 6):\n",
    "        \"\"\"Uses the node features of the graph and generates a feature/target\n",
    "        relationship of the shape\n",
    "        (num_nodes, num_node_features, num_timesteps_in) -> (num_nodes, num_timesteps_out)\n",
    "        \n",
    "\n",
    "        Args:\n",
    "            num_timesteps_in (int): number of timesteps the sequence model sees\n",
    "            num_timesteps_out (int): number of timesteps the sequence model has to predict\n",
    "        \"\"\"\n",
    "        time_steps_starter =   36 # it can be assigned as one of the following {0, 12, 24, 36}\n",
    "        indices = [\n",
    "            (i, i +time_steps_starter+ (num_timesteps_in + num_timesteps_out))\n",
    "            for i in range(self.data_norm.shape[2] - (time_steps_starter+num_timesteps_in + num_timesteps_out) + 1)\n",
    "        ]\n",
    "        print(indices)\n",
    "        # Generate observations\n",
    "        features, target = [], []\n",
    "        for i, j in indices:\n",
    "            features.append((self.data_norm[:, :, i : i + num_timesteps_in]).numpy().transpose(\n",
    "            (2, 0, 1)\n",
    "        ))\n",
    "            target.append((self.data_norm[  :, 0, i + num_timesteps_in +time_steps_starter: j]).numpy())\n",
    "\n",
    "        self.features = features\n",
    "        self.targets = target\n",
    "\n",
    "    def get_dataset(\n",
    "        self, num_timesteps_in: int = 6, num_timesteps_out: int = 6\n",
    "    ) -> StaticGraphTemporalSignal:\n",
    "        \"\"\"Returns data iterator for the dataset as an instance of the\n",
    "        static graph temporal signal class.\n",
    "\n",
    "        Return types:\n",
    "            * **dataset** *(StaticGraphTemporalSignal)* - The forecasting dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._generate_task(num_timesteps_in, num_timesteps_out)\n",
    "        dataset = StaticGraphTemporalSignalBatch(\n",
    "            self.edges, self.edge_weights, self.features, self.targets, self.batch\n",
    "        )\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dr8XG4l0qWv0"
   },
   "outputs": [],
   "source": [
    "loader = MadridDatasetLoader(data_test_norm, edges, edge_weights, batch)\n",
    "dataset_test = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
    "print(\"Dataset type:  \", dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtnqZzRGqbIG"
   },
   "outputs": [],
   "source": [
    "loader = MadridDatasetLoader(data_norm, edges, edge_weights, batch)\n",
    "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
    "print(\"Dataset type:  \", dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWufZl52s3ev"
   },
   "outputs": [],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTPLYwWrrAm7",
    "outputId": "0966c1c4-5212-427e-ebd8-482930a9dda6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalGNN(\n",
       "  (tgnn): TGCN2(\n",
       "    (conv_z): GCNConv(18, 256)\n",
       "    (linear_z): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (conv_r): GCNConv(18, 256)\n",
       "    (linear_r): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (conv_h): GCNConv(18, 256)\n",
       "    (linear_h): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define TGCN\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    set_seed(rnd_seed)\n",
    "\n",
    "unit_num  = 256 # This is number of units in order to construct the architecture of the TGCN. \n",
    "class TemporalGNN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(TemporalGNN, self).__init__()\n",
    "        # Temporal Graph Convolutional Cell\n",
    "        self.tgnn = TGCN2(in_channels=node_features, \n",
    "                        out_channels=unit_num, batch_size=12)\n",
    "        # Equals single-shot prediction\n",
    "        self.linear = torch.nn.Linear(unit_num, 12)\n",
    "\n",
    "    def forward(self, x, edge_index,  edge_weight):\n",
    "        \"\"\"\n",
    "        x = Node features for T time steps\n",
    "        edge_index = Graph edge indices\n",
    "        \"\"\"\n",
    "        h = self.tgnn(x, edge_index,  edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "TemporalGNN(node_features=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS0ChRHVrEom",
    "outputId": "16c36497-cce0-427e-a0b5-82ea8d8081da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training...\n",
      "Epoch 0 train MSE: 0.9955\n"
     ]
    }
   ],
   "source": [
    "# GPU support\n",
    "device = torch.device('cpu') # cuda\n",
    "\n",
    "\n",
    "# Create model and optimizers\n",
    "model = TemporalGNN(node_features=18).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "print(\"Running training...\")\n",
    "for epoch in range(100): \n",
    "    loss = 0\n",
    "    step = 0\n",
    "    for snapshot in dataset:\n",
    "        snapshot = snapshot.to(device)\n",
    "        # Get model predictions\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        # Mean Squared Error\n",
    "        loss = loss + torch.mean((y_hat-snapshot.y)**2) \n",
    "        step += 1\n",
    "        \n",
    "\n",
    "    loss = loss / (step + 1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4A2aYqACF1DE"
   },
   "outputs": [],
   "source": [
    "# it is calculated for all nodes\n",
    "\n",
    "ALLNode_pred = []\n",
    "ALLNode_true = []\n",
    "for item in predictions:\n",
    "    for batch in range(12):\n",
    "        for node in range(24):\n",
    "            for hour in range(12):\n",
    "                ALLNode_pred.append(item[batch][node][hour].detach().cpu().numpy().item(0))\n",
    "\n",
    "\n",
    "for item in labels:\n",
    "    for node in range(24):\n",
    "        for hour in range(12):\n",
    "            ALLNode_true.append(item[node][hour].detach().cpu().numpy().item(0))\n",
    "\n",
    "\n",
    "ALLNode_pred_np = np.array(ALLNode_pred)\n",
    "ALLNode_pred_np_resh = ALLNode_pred_np.reshape(-1, 12, 24, 12)\n",
    "ALLNode_true_np = np.array(ALLNode_true)\n",
    "ALLNode_true_np_resh = ALLNode_true_np.reshape(-1, 24, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cYmTVsDarIYl"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "loss = 0\n",
    "step = 0\n",
    "\n",
    "# Store for analysis\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for snapshot in dataset_test:\n",
    "    snapshot = snapshot.to(device)\n",
    "    # Get predictions\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    yhat_reverse = reverse_zscore(y_hat, means[0], stds[0])\n",
    "    snapshot.y_reverse = reverse_zscore(snapshot.y, means[0], stds[0])\n",
    "    # Mean Absolute Error\n",
    "    loss = loss + torch.mean(torch.abs(yhat_reverse-snapshot.y_reverse))\n",
    "    # Store for analysis below\n",
    "    labels.append(snapshot.y_reverse)\n",
    "    predictions.append(yhat_reverse)\n",
    "    step += 1\n",
    "  \n",
    "\n",
    "loss = loss / (step+1)\n",
    "loss = loss.item()\n",
    "print(\"Test MAE: {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IU-4otmCF3H"
   },
   "outputs": [],
   "source": [
    "ALLNode_pred_np_resh_Update = np.mean(ALLNode_pred_np_resh, axis=1)\n",
    "true = ALLNode_true_np_resh.reshape(-1)\n",
    "pred = ALLNode_pred_np_resh_Update.reshape(-1)\n",
    "rmse = mean_squared_error(true, pred, squared=False)\n",
    "mae = mean_absolute_error(true, pred)\n",
    "scipy.stats.pearsonr(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIylBL5Dujrm"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCB5u6Ei1V46"
   },
   "outputs": [],
   "source": [
    "# standardise train data\n",
    "\n",
    "data = fin_data.transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "data = data.astype(np.float32)\n",
    "\n",
    "# standardise (via Z-Score Method)\n",
    "means = np.mean(data, axis=(0, 2))\n",
    "data_norm= data-means.reshape(1, -1, 1)\n",
    "stds = np.std(data_norm, axis=(0, 2))\n",
    "data_norm= data_norm/ stds.reshape(1, -1, 1)\n",
    "fin_data_norm = data_norm.transpose(2, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RaX5h41QUvk",
    "outputId": "6d0106aa-0095-4063-c769-0d523c8e2562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4344, 24, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XblUgo_GTldw"
   },
   "outputs": [],
   "source": [
    "# standardise test data\n",
    "\n",
    "data_test = fin_data_test.transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "data_test = data_test.astype(np.float32)\n",
    "data_test_norm= data_test- means.reshape(1, -1, 1)\n",
    "data_test_norm= data_test_norm/ stds.reshape(1, -1, 1)\n",
    "fin_data_test_norm = data_test_norm.transpose(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-GPFJVGTdia",
    "outputId": "bcf49d24-d7c2-4064-cda7-46475e917d44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4343, 24, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyrT376CXEE1"
   },
   "outputs": [],
   "source": [
    "# split dataset to X and y (dependent and independent)\n",
    "\n",
    "def split_sequence(sequence, seq_notNorm, time_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "   \n",
    "        # find the end of this pattern\n",
    "        end_ix = i +12\n",
    "        time_steps_starter = 0 # it can be assigned as one of the following {0, 12, 24, 36}\n",
    "\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix+time_steps_starter+time_steps > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern    \n",
    "        seq_x, seq_y = sequence[i:end_ix], seq_notNorm[end_ix+time_steps_starter:end_ix+time_steps_starter+time_steps]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "\n",
    "# choose a number of time steps \n",
    "time_steps = 12\n",
    "X_train, y_train = split_sequence(fin_data_norm, fin_data_norm, time_steps)\n",
    "X_test, y_test = split_sequence(fin_data_test_norm, fin_data_test_norm, time_steps)\n",
    "\n",
    "# to select only nitrogen dioxide as a target feature\n",
    "y_train = y_train[:, :, :, 0]\n",
    "y_test = y_test[:, :, :, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TijYCg8j3_49",
    "outputId": "421850c3-94c9-4eb1-cad8-693fb7b5e663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4319, 12, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9sVQ3kJXpS9",
    "outputId": "8d938829-8fe3-47cd-882c-1372aa7adb16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 12, 24, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Te68AEaDjgf2"
   },
   "outputs": [],
   "source": [
    "# reshape the data for LSTM input\n",
    "\n",
    "number_selected_columns =18\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 24*number_selected_columns))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 24*number_selected_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVf6syYcafEb",
    "outputId": "bae0f38b-8e21-4b11-8dfa-6d7f269b3e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 11\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "  set_seed(rnd_seed)\n",
    "  model = Sequential()\n",
    "  model.add(Dense(432,input_shape=(X_train.shape[1], 24*number_selected_columns)))\n",
    "  model.add(LSTM(512, return_sequences=True))\n",
    "  model.add(Dense(24))\n",
    "  model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXuHvfdJbKdj"
   },
   "outputs": [],
   "source": [
    "# run LSTM\n",
    "\n",
    "lstm_model = model.fit(X_train_reshaped, y_train, epochs=100, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzu0SlJezwvO",
    "outputId": "41b86766-6afe-45b8-fd35-da7edb588387"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4319, 12, 24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0AZoRmFkT5z",
    "outputId": "c09956ff-911c-4218-a32c-b98b622a0678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test_reshaped, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7j5AVX_IvXmy"
   },
   "outputs": [],
   "source": [
    "yhat_reverse = reverse_zscore(yhat, means[0], stds[0])\n",
    "ytest_reverse = reverse_zscore(y_test, means[0], stds[0])\n",
    "yhat_reshaped = yhat_reverse.reshape(-1,24)\n",
    "y_test_reshaped= ytest_reverse.reshape(-1,24)\n",
    "rmse = mean_squared_error(yhat_reshaped, y_test_reshaped, squared=False)\n",
    "mae = mean_absolute_error(yhat_reshaped, y_test_reshaped)\n",
    "print('Test Score: %.2f RMSE' % (rmse))\n",
    "print('Test Score: %.2f MAE' % (mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHawxiO1vZ-d"
   },
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(yhat_reshaped.reshape(-1), y_test_reshaped.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy-VBluzB7Vw"
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXBobptkCIg4"
   },
   "outputs": [],
   "source": [
    "# standardise train data\n",
    "\n",
    "data = fin_data.transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "data = data.astype(np.float32)\n",
    "\n",
    "# standardise (via Z-Score Method)\n",
    "means = np.mean(data, axis=(0, 2))\n",
    "data_norm= data-means.reshape(1, -1, 1)\n",
    "stds = np.std(data_norm, axis=(0, 2))\n",
    "data_norm= data_norm/ stds.reshape(1, -1, 1)\n",
    "fin_data_norm = data_norm.transpose(2, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGSpkn83CMWc",
    "outputId": "6d0106aa-0095-4063-c769-0d523c8e2562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4344, 24, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3U7HiQAwCPmK"
   },
   "outputs": [],
   "source": [
    "# standardise test data\n",
    "\n",
    "data_test = fin_data_test.transpose(\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "data_test = data_test.astype(np.float32)\n",
    "data_test_norm= data_test- means.reshape(1, -1, 1)\n",
    "data_test_norm= data_test_norm/ stds.reshape(1, -1, 1)\n",
    "fin_data_test_norm = data_test_norm.transpose(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C65QpL6-CSFe",
    "outputId": "bcf49d24-d7c2-4064-cda7-46475e917d44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4343, 24, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtsDvv5wCU_0"
   },
   "outputs": [],
   "source": [
    "# split dataset to X and y (dependent and independent)\n",
    "\n",
    "def split_sequence(sequence, seq_notNorm, time_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "   \n",
    "        # find the end of this pattern\n",
    "        end_ix = i +12\n",
    "        time_steps_starter = 0 # it can be assigned as one of the following {0, 12, 24, 36}\n",
    "\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix+time_steps_starter+time_steps > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern    \n",
    "        seq_x, seq_y = sequence[i:end_ix], seq_notNorm[end_ix+time_steps_starter:end_ix+time_steps_starter+time_steps]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "\n",
    "# choose a number of time steps \n",
    "time_steps = 12\n",
    "X_train, y_train = split_sequence(fin_data_norm, fin_data_norm, time_steps)\n",
    "X_test, y_test = split_sequence(fin_data_test_norm, fin_data_test_norm, time_steps)\n",
    "\n",
    "# to select only nitrogen dioxide as a target feature\n",
    "y_train = y_train[:, :, :, 0]\n",
    "y_test = y_test[:, :, :, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0gHvoXiCZ01",
    "outputId": "421850c3-94c9-4eb1-cad8-693fb7b5e663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4319, 12, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXhCwIyrCc6T",
    "outputId": "8d938829-8fe3-47cd-882c-1372aa7adb16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 12, 24, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8_9VpbSutmO"
   },
   "outputs": [],
   "source": [
    "\n",
    "# reshape the data for GRU input\n",
    "\n",
    "number_selected_columns =18\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 24*number_selected_columns))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 24*number_selected_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A_lSpItuvuf",
    "outputId": "c76d28c7-881e-44ce-b22e-c8e3e9ff85e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 11\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    set_seed(rnd_seed)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(432,input_shape=(X_train.shape[1], 24*number_selected_columns)))\n",
    "    model.add(GRU(512, return_sequences=True))\n",
    "    model.add(Dense(24))\n",
    "    model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "j1_ZirvzuxTG"
   },
   "outputs": [],
   "source": [
    "# run GRU\n",
    "\n",
    "gru_model = model.fit(X_train_reshaped, y_train, epochs=100, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIFDmFmJndfx",
    "outputId": "6ecc23c0-aae5-4098-f043-7902e6bbd7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 4s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test_reshaped, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Q5kp-PwwnhA3"
   },
   "outputs": [],
   "source": [
    "yhat_reverse = reverse_zscore(yhat, means[0], stds[0])\n",
    "ytest_reverse = reverse_zscore(y_test, means[0], stds[0])\n",
    "yhat_reshaped = yhat_reverse.reshape(-1,24)\n",
    "y_test_reshaped= ytest_reverse.reshape(-1,24)\n",
    "rmse = mean_squared_error(yhat_reshaped, y_test_reshaped, squared=False)\n",
    "mae = mean_absolute_error(yhat_reshaped, y_test_reshaped)\n",
    "print('Test Score: %.2f RMSE' % (rmse))\n",
    "print('Test Score: %.2f MAE' % (mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JTCzNkMb-37H"
   },
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(yhat_reshaped.reshape(-1), y_test_reshaped.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FOk9DhIaC5an"
   },
   "outputs": [],
   "source": [
    "#======================================================-========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required libraries \n",
    "\n",
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
    "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
    "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
    "!pip install torch-geometric\n",
    "!pip install torch-geometric-temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
